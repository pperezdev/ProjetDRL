########## GLOSSAIRE

s,s': Un état
a: Un action
r: Une récompense
S: Ensemble des états non terminaux
S+: Ensemble des états (inclue les états terminaux)
A(s): Ensemble d'action dans un état s
R: Ensemble des récompenses disponibles
π: Stratégie
π(s): Action prise depuis l'état s en suivant la stratégie π
π(a|s): Probabilité d'executer une action a depuis l'état s selon la stratégie π
p(s',r|s,a): Probabilité de transition s->s' avec récompense en effectuant l'action a
p(s'|s,a): Probabilité de transition s->s' en effectuant l'action a
r(s,a): Récompense de l'état s après l'action a
r(s,a,s'): Récompense de la transition s->s' selon l'action a

states-value function:
    v_π(s): Valeur de l'état s selon la stratégie π
    v_*(s): Valeur de l'état s selon la stratégie π optimal

action-values fonction:
    q_π(s,a): Valeur de prendre l'action a depuis l'état s selon la stratégie π
    q_*(s,a): Valeur de prendre l'action a depuis l'état s selon la stratégie π optimal

V ou Vt: Tableau d'estimations de la fonction état-valeur (states-value function: v_π ou v_*)
Q ou Qt: Tableau d'estimations de la fonction action-valeur (action-value function: q_π ou q_*)